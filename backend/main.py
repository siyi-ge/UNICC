from fastapi import FastAPI, UploadFile, File, Request as FastAPIRequest
from google.auth.transport.requests import Request as GoogleAuthRequest
from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from google.oauth2 import service_account
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import torch
import base64
import json
import os
import requests
import whisper
import tempfile
import sys
from pydub import AudioSegment
import nltk
import vertexai
from vertexai.generative_models import GenerativeModel, SafetySetting
from googleapiclient import discovery
import shutil
from run_pipeline import run_pipeline_main
import inspect


app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # æµ‹è¯•æ—¶å…è®¸æ‰€æœ‰æº
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("startup")
async def print_routes():
    print("âœ… Registered routes:")
    for route in app.routes:
        print(f"â†’ {route.path} [{route.methods}] -> {inspect.getsourcefile(route.endpoint)}")

#è½¬å½•éŸ³é¢‘æ–‡ä»¶ä¸ºæ–‡æœ¬
whisper_model= whisper.load_model("base")  # åŠ è½½ Whisper æ¨¡å‹ä¸€æ¬¡å³å¯
print("ğŸ§  Whisper æ¨¡å‹å·²åŠ è½½")  # âœ… è¿™å¥èƒ½å¦è¾“å‡º


@app.post("/analyze/Whisper")
async def analyze_whisper(file: UploadFile = File(...)):
    # å°†ä¸Šä¼ çš„éŸ³é¢‘ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
        tmp.write(await file.read())
        tmp_path = tmp.name

    try:
        print("ğŸ§ å¼€å§‹è°ƒç”¨ Whisper è½¬å†™...")
        result = whisper_model.transcribe(tmp_path)
        transcript = result["text"]

        result = await analyze_text(transcript)

        return {
            "transcript": transcript,
            **result  # è¿”å› label / perspective_summary / sentence_analysis
        }

    except Exception as e:
        print("âŒ Whisper è½¬å†™å¤±è´¥ï¼š", str(e))  # âœ… æ‰“å°é”™è¯¯
        return { "error": str(e) }



app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


nltk.download('punkt')
nltk.download('punkt_tab')  # ğŸ‘ˆ å°±æ˜¯è¿™ä¸ª

# Google Cloud Service Account é…ç½®
SERVICE_ACCOUNT_FILE = "thermal-origin-454105-s5-c6291f413f44.json"
SCOPES = ["https://www.googleapis.com/auth/cloud-platform"]

credentials = service_account.Credentials.from_service_account_file(
    SERVICE_ACCOUNT_FILE, scopes=SCOPES
)
credentials.refresh(GoogleAuthRequest())
access_token = credentials.token

# Vertex AI Gemini æ¨¡å‹è®¾ç½®
vertexai.init(
    project="thermal-origin-454105",
    location="us-central1",
    api_endpoint="us-central1-aiplatform.googleapis.com"
)

gemini_model = GenerativeModel(
    model_name="projects/829020429280/locations/us-central1/endpoints/6002987141494210560"
)
chat = gemini_model.start_chat()

# Perspective API è®¾ç½®
API_KEY = "AIzaSyDGwQzJDQe_lJv7YnhnM3JFjQDA0HRZUf8"
perspective_client = discovery.build(
    "commentanalyzer",
    "v1alpha1",
    developerKey=API_KEY,
    discoveryServiceUrl="https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1",
    static_discovery=False,
)

# ğŸ” æ‹†å¥ + Gemini + Perspective åˆ†æ
async def analyze_text(text):
    sentences = nltk.sent_tokenize(text)
    prompt_suffix = "\n\nPlease determine whether this sentence is toxic; if it is, output 'toxic', if it is not, output 'non-toxic':\n\n"
    sentence_analysis = []
    is_toxic = False

    # æ•´ä½“ Perspective API åˆ†æ
    perspective_summary = perspective_client.comments().analyze(
        body={
            "comment": {"text": text},
            "requestedAttributes": {
                "TOXICITY": {},
                "SEVERE_TOXICITY": {},
                "INSULT": {},
                "PROFANITY": {},
                "THREAT": {},
                "IDENTITY_ATTACK": {}
            }
        }
    ).execute().get("attributeScores", {})

    for sentence in sentences:
        # Gemini å›ç­”æ˜¯å¦ toxic
        try:
            gemini_reply = chat.send_message(sentence + prompt_suffix)
            gemini_label = gemini_reply.text.strip().lower()
        except Exception:
            gemini_label = "unknown"

        if gemini_label == "toxic":
            is_toxic = True

        # Perspective åˆ†æå•å¥
        try:
            toxicity_scores = perspective_client.comments().analyze(
                body={
                    "comment": {"text": sentence},
                    "requestedAttributes": {
                        "TOXICITY": {},
                        "SEVERE_TOXICITY": {},
                        "INSULT": {},
                        "PROFANITY": {},
                        "THREAT": {},
                        "IDENTITY_ATTACK": {}
                    }
                }
            ).execute().get("attributeScores", {})
        except:
            toxicity_scores = {}

        sentence_analysis.append({
            "sentence": sentence,
            "gemini_label": gemini_label,
            "toxicity_scores": toxicity_scores
        })

    return {
        "label": "toxic" if is_toxic else "non-toxic",
        "perspective_summary": perspective_summary,
        "sentence_analysis": sentence_analysis
    }

# === HuggingFace Text Classification Setup ===
# åŠ è½½ fine-tuned æ¨¡å‹å’Œ tokenizerï¼ˆåªéœ€åŠ è½½ä¸€æ¬¡ï¼‰
classification_model= XLMRobertaForSequenceClassification.from_pretrained("momoali23/finetuned-xlm-r-tweeteval-hate")
tokenizer = XLMRobertaTokenizer.from_pretrained("momoali23/finetuned-xlm-r-tweeteval-hate")

@app.post("/analyze/fine-tuned")
async def analyze_custom_model(request: FastAPIRequest):
    data = await request.json()
    text = data.get("text", "")

    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = classification_model(**inputs)
        prediction = torch.argmax(outputs.logits, dim=1).item()
        score = torch.softmax(outputs.logits, dim=1).max().item()

    label_map = {
        0: "âœ… Normal",
        1: "ğŸš¨ Hate Speech"
    }

    return {
        "label": label_map[prediction],
    }

# === HuggingFace Video Setup ===
model_path = "./classifier_trained"  # æœ¬åœ°è·¯å¾„ï¼Œç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)

classifier = pipeline("text-classification", model=model, tokenizer=tokenizer)


@app.post("/analyze/video")
async def analyze_video_fastapi(file: UploadFile = File(...)):
    video_path = "uploaded_video.mp4"
    output_dir = "outputs/video_analysis"

    # ä¿å­˜ä¸Šä¼ çš„è§†é¢‘
    with open(video_path, "wb") as f:
        f.write(await file.read())

    # æ‰§è¡Œåˆ†ææµç¨‹ï¼ˆæ¯”å¦‚ Whisper + OCR + åˆ†ç±»å™¨ï¼‰
    try:
        run_pipeline_main(video_path, output_dir)
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})

   # åŠ è½½ prediction.json
    pred_file = os.path.join(output_dir, "prediction.json")
    if not os.path.exists(pred_file):
        return JSONResponse(status_code=500, content={"error": "Prediction result not found"})

    with open(pred_file, "r", encoding="utf-8") as f:
        prediction_data = json.load(f)

        # ç»Ÿè®¡ top labelï¼ˆå¦‚ hate_speech/offensive_speech/noneï¼‰
        label_counts = {"hate_speech": 0, "offensive_speech": 0, "none": 0}
        for p in prediction_data:
            label_counts[p["label"]] += 1
        top_label = max(label_counts.items(), key=lambda x: x[1])[0]

        # è¿”å›æ–‡æœ¬å†…å®¹+top label
        return JSONResponse(content={
            "label": top_label,
            "texts": [p["text"] for p in prediction_data]
        })



